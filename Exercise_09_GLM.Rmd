---
title: "Lab 09: Linear Model Extentions"
author: "GE 509"
date: "October 20, 2014"
output: html_document
---

The objective of this lab is to apply the techniques we have been learning about ways to relax the assumptions of linear models and to gain additional practice with Likelihood and Bayesian models of progressively greater complexity.  Specifically, we will start from a Generalized Linear Models framework, and then additionally consider techniques for dealing with 'errors in variables' and missing data. In this lab you will be presented with the code for the model itself but will be asked to apply what you've learned in previous labs to complete the rest of the analysis. 

Note: As in the previous MCMC labs, the number of samples required for publication-quality inference is a good bit larger than the number we expect you to run in lab.  In general, it is better to thin less than to estimate with a very small MCMC sample size provided your posterior densities are smooth and unimodal.  If the posteriors have multiple modes due to slow mixing or lack of convergence they you just have to run longer.

## Case Study:  Seedling Recruitment and Soil Moisture

In this analysis we'll consider the relationship between soil moisture and seedling densities.  The response data (y) in this analysis consists of counts of seedlings in 1m x 1m plots.  Soil moisture was measured using Time Domain Reflectometry (TDR), a technique where two metal rods are inserted into the ground and an electrical pulse is sent down one rod and measured on the other.  The TDR technique actually measures soil impedance, not soil moisture, but soil moisture can be estimated based on empirical calibrations against gravimetric soil moisture measurements (difference between wet and dry weight of soil cores).  TDR has the advantage of being much less labor intensive and non-destructive than gravimetric measurement, which permits repeated measurements of the same plots.
  The Poisson distribution is a natural choice for modeling the seedling count data because the data is both discrete and lacking a defined upper bound.  Since we are interested in the relationship between seedling density and a covariate, soil moisture, we'll make use of the Generalized Linear Models (GLM) framework for fitting a Poisson regression.  As a link function, lets start with the standard choice of a log link.
 
$$log(\mu) = \beta_0 + \beta_1 TDR$$
$$y \sim Pois(\mu)$$
 
The data for this analysis are provided to you as a R data object that contains the following variables:

	n – sample size
	y – seedling counts (individuals/m2)
	TDR – raw output from the TDR unit (arbitrary units) for each seedling plot
	TDRc – raw TDR output for the calibration samples
	SMc – Volumetric soil moisture measurements for the calibration samples (m3/m3)
	SMseq – a sequence of soil moisture values used for prediction

```{r}
load("data/Lab9.RData")
```

For the first part of this analysis we will use the TDR measurements as our covariate.  We will deal with the calibration issue later in the lab.

## Maximum Likelihood Poisson Regression

To begin, open up R and load the data file in order to perform some exploratory data analysis and to look at the analysis from a Likelihood perspective.  As a reminder from lecture, the Likelihood analysis could be performed two ways in R.  The first would be to use the “glm” function

```{r}
PR1 = glm(y ~ TDR, family=poisson(link="log"))
```

The second approach would be to define the negative log likelihood function yourself and then use a nonlinear optimization function (e.g. nlm, optim) to find the MLE
 
```{r}
ic=c(0,0)
LnL = function(beta){
  -sum(dpois(y,exp(beta[1] + beta[2]*TDR),log=TRUE))
}
PR2 = nlm(LnL,ic)
```

### Lab Report Task 1

1.  Plot seedling densities as a function of TDR
2.	Fit the Poisson regression model using one of the methods above and turn in  the summary output (hint: for the second method you will need to define the initial condition vector ic) 
3.	Add regression lines to the plot
Hint 1: use “coef” to extract the regression coefficients from the GLM.
Hint 2: don't forget about the link function when plotting the lines
4.	Briefly describe how you would add model confidence and predictive intervals to these curves
5.	What would be an appropriate null model to compare to?  What metric would you use to compare the two models?
6.	Plot the calibration data of TDR vs. soil moisture.  Fit a Normal regression model to the calibration data, add the line to the plot, and report the summary table information for the fit


## Bayesian Poisson Regression

Next we're going to fit the Poisson regression model from the Bayesian perspective using BUGS.  This will allow you to compare the Likelihood and Bayesian approaches and will serve as the foundation for building a more complex model.  As discussed in lecture, the Poisson regression model in BUGS is

```{r}
PoisReg = "
model {
  for(i in 1:2) { beta[i] ~ dnorm(0,0.001)}    ## priors
  for(i in 1:n){
    log(mu[i]) <- beta[1]+beta[2]*TDR[i]     ## process model
    y[i] ~ dpois(mu[i])  			## data model
    py[i] ~ dpois(mu[i])			## Prediction
  }
}
"
```

The process and data model here are identical to that in the likelihood approach above, with the link function showing up on the left hand side of the arrow for the process model.  For priors we'll assume fairly weak Normal priors on the regression parameters (beta).  The final line where we compute py looks identical to the line before it where we calculate the likelihood of y, but the critical difference is that the y's are the data and thus are KNOWN, while the py's (predicted y's) are not and will be used to construct the model predictive intervals.  BUGS will recognize this distinction when you go to the “load data” step and it sees that the y's are specified and the py's are not.  Since the y's are given BUGS knows that you are saying that the data has this likelihood, while since the py's are not specified BUGS knows that you want the py's to be random numbers drawn from the Poisson.  Alternatively, if the py's HAD been specified as an independent data set (e.g. counts of a second species), then BUGS would have instead interpreted this as a second likelihood and found the posterior distribution based on both datasets.
 
### Lab Report Task 2: 

7.  Fit the Bayesian Poisson regression model. Provide the DIC and a summary table and posterior density plots for the model parameters.  Also report the number of chains, length of each chain,  burn in, thin, and the resultant MCMC sample size used to estimate the parameters (You should still be making diagnostic plots but you no longer need to include them).  Reminder: If you use the OpenBUGS GUI you will need to use “dput” to export the data from R into list format and cut-and-paste it into your BUGS script (Hint: see lab 7), otherwise you will need to use the R interface (see lab 10)
8.	Compare the parameters from the Bayesian fit to the Likelihood fit.  Make sure to identify which terms match with which between the models.
9.	Use the Comparison Tool to plot the model credible interval and predictive interval.  Be sure to include the scatterplot of the observed data.
10.	How well does the Poisson model match the data?  Does 95% of the data fall within the 95% PI?

## Missing Data

It is not uncommon in the real world for a small percentage of data to be missing due to any of a multitude of real-world mistakes. In many cases it is simple enough to 'drop' these data, as is the norm in classical analyses. However there are cases where this is undesirable, such as when one has a large number of covariates and you are only missing one and don't want to drop the whole row, or when individual measurements are very expensive in time or money or are otherwise irreplaceable.  From the Bayesian perspective it is possible to formally accommodate missing data by [numerically] integrating over all possible states the data can take on.  This technique is sometime referred to as imputing the missing data, or more specifically as multiple imputation because we are proposing many values the data could have been.  Doing this (not surprisingly) requires that we specify a prior distribution on the missing data itself.  However, the inference will draw on the likelihood, the other covariates, and the response data in order to formally generate the posterior distribution of the missing data. Therefore, it is the posterior that we actually using 'fill in' the missing data, not the prior.  Finally, it bears mentioning that addressing missing data requires that we meet one very important assumtion – that the data is missing at random.  If the process that caused the data to be missing is systematic or in any way related to the process we're trying to understand then we cannot impute the missing data.

To show how this works, within our BUGS script lets make a copy of our data and then randomly change one of the TDR values to NA in order to make it 'missing'.  You'll then want to re-run the regression model using this data, but this time add the TDR value you removed to the variables that you track (e.g. TDR[12] if you removed the 12th TDR measurement) so that we can view the posterior distribution.  In order for the model to run you will need to specify a PRIOR distribution on that same missing TDR value within your BUGS code (e.g. a uniform over the range of valid data).

### Lab Report Task 3: 
17.  Report the posterior distributions of the missing TDR data.  How does this compare to the prior your specified and to the true value?

 
## Bayesian Negative Binomial Regression (Extra Credit)

As we've discussed a number of times, one interpretation of the Negative Binomial model is as a Poisson-Gamma mixture whereby the mean of the Poisson varies with a Gamma distribution rather than being a fixed number.  The result of this is a distribution that has similar properties to the Poisson but has a higher variance (recall that for the Poisson the mean and variance both equal $\lambda$ ).  We will now modify the Poisson regression model above to be generalized to be a Negative Binomial regression.  Unfortunately, the default implementation of the Negative Binomial PDF in BUGS, dnegbin(p,r), assumes the traditional parameterization of the model whereby the first parameter, p, is the probability of failure and  the second parameter, r, is the number of failures.  As such it only allows r to take on integer values.  In the alternative parameterization based on the Poisson-Gamma mixture the r parameter is the “shape” term in the Gamma and is a continuous number.  Most importantly, this parameter is the one we will use to control the amount of “extra-Poisson” variance in the Negative Binomial.  Because of this limitation we will explicitly implement the Negative Binomial as a Poisson-Gamma mixture.  The Gamma(r,b) in BUGS has a mean of r/b, therefore holding r constant we find that b = r/E[y].  Putting this all together we have the model
 
$$log(mu) = \beta_0 + \beta_1 TDR$$
$$y \sim NegBinom(\mu,r)$$
$$\beta \sim N(B_0,V_b)$$
$$r ~ sim Unif(r_low,r_hi)$$

Here we have little prior expectation about how r is distributed other than it must be positive so we assume a broad but finite uniform prior.
 
```{r}
NegBinomReg = "
model {
  for(i in 1:2) { beta[i] ~ dnorm(0,0.001)}   ## priors
  r ~ dunif(0,100)
  for(i in 1:n){
            log(mu[i]) <- beta[1]+beta[2]*TDR[i]   ## process model
  b[i] <- r/mu[i]
	lambda[i] ~ dgamma(r,b[i])                   ## data model
            y[i] ~ dpois(lambda[i])
	lambdap[i] ~ dgamma(r,b[i])                 ## prediction
            py[i] ~ dpois(lambdap[i])
   }
}
"
```

When running this model you may find that the initial conditions generated randomly from “Gen Inits” are too broad and result in a model that crashes (reminder: save early, save often, and save before running any model).  In this case you will want to specify initial conditions for the parameters (see Lab 5 for help).  As a reminder it is perfectly valid to use the data to set the initial conditions (e.g. the regression parameters from the Poisson model).  Also, r should be between about 0.5 and 2.

### Lab Report Task 4: 

12. Fit the Negative Binomial regression model and provide a summary table and posterior density plots for the model parameters.  Only provide estimates for those variables which are model parameters.  Also report the number of chains, length of each chain, burn in, thin, and the resultant MCMC sample size used to estimate the parameters (You should still be making diagnostic plots but you no longer need to include them). 
13. Use the Comparison Tool to plot the model credible interval and predictive interval.  Be sure to include the scatterplot of the observed data.
14. How well does the Negative Binomial model match the data?  How does this fit compare to the Poisson in terms of capturing the observed range of variability?  Include the DIC scores from the two models and interpret them.  What impact does the change in likelihood have on the regression parameters?
 

### Poisson Regression with Errors in Variables

Note: the first two models presented below are for explanation and you don't have to run them

One obvious problem with the analyses conducted so far is that the covariate has been our proxy data, TDR, which has arbitrary units and is not biologically interesting  -- there are no noteworthy theories in biology about the effect of soil impedance on plants.  What we are really interested in is the impact of soil moisture on our plants, but we never observe soil moisture directly – it is a latent variable.  However, we do have a calibration curve that can be used to relate TDR to soil moisture.  By far the most common approach in the literature to calibration problems such as this one is to use just only the deterministic process model for the relationship between the two variables in order to transform one variable to another.  However, the relationship is not perfect and therefore there is uncertainty in the soil moisture estimates.  A full treatment of uncertainty would account for the fact that there is both parameter uncertainty in the calibration curve and residual error in the data model – in other words we want to know the posterior predictive distribution of each soil moisture estimate given the observed TDR measurement.  If we knew this we could then use these posterior distributions as informative priors on our data model for the Errors in Variables model we talked about in lecture.  If we wanted to fit the calibration curve in BUGS it would just be the simple linear regression model we've seen a number of times already
 
```
model {
  for(i in 1:2) { alpha[i] ~ dnorm(0,0.001)}   ## priors
  sigma ~ dgamma(0.01,0.01)
  for(i in 1:10){
            ESMc[i] <- alpha[1]+alpha[2]*TDRc[i]   ## process model: Expected SMc
            SMc[i] ~ dnorm(ESMc[i],sigma)           ## data model: Soil Moisture calibration
   }
}
```

The Poisson regression model would then be modified based on the errors in variable approach to account for the uncertainty in soil moisture due to the fact that TDR is an imperfect proxy.  In this case the priors on the error model for soil moisture (alpha, sigma) would be the posteriors from the calibration model above.  In order to actually use alpha and sigma as priors for the errors in variables model we need to approximate the posteriors with some distribution – for example alpha[1] may be approximately normal and thus could be approximated by dnorm(abar[1],aprec[1]) where abar is the posterior mean and aprec is the posterior precision.  We could similarly approximate the posterior or sigma with a gamma(s1,s2) where s1 and s2 could be found based on the posterior mean and variance of sigma.
 
```
model {
  for(i in 1:2) { alpha[i] ~ dnorm(abar[i],aprec[i])}    ## informative calibration priors
  sigma ~ dgamma(s1,s2)
  for(i in 1:2) { beta[i] ~ dnorm(0,0.001)}    ## regression priors
  for(i in 1:n){
    ESM[i] <-  alpha[1] + alpha[2]*TDR[i]   ## Errors in variables model
    SM[i] ~ dnorm(ESM[i],sigma)
    log(mu[i]) <- beta[1]+beta[2]*SM[i]        ## process model
    y[i] ~ dpois(mu[i])  			## data model
    py[i] ~ dpois(mu[i])			## Prediction
  }
}
```

An alternative approach to fitting each model individually and then passing information between them would be to fit both models simultaneously.  The advantages of this are that we don't have to move information between models and that we don't have to make assumptions about approximating the shape of the posterior distributions of alpha and sigma.  Also, when performing the analysis sequentially information only flows in one direction, while when done simultaneously both models borrow strength from one another  The disadvantages are that the final code is longer and that the overall MCMC might mix a little slower.  In practice, the difference in output between the two approaches (sequential vs combined) should be small and the decision on which approach to use is often a practical one – for analyses with large data sets sequential analysis is often more practical even if the combined analysis may be slightly preferred conceptually.  Furthermore, for the specific issue of calibration presented here we often do not have access to the original calibration data set and are forced to rely on summary statistics about the accuracy of a proxy to construct our priors.

Writing the combined model (below) involves little more than putting the code for each of these two models into one file

```{r}
PoisRegPlusCalib = "
model {
  ### TDR calibration curve
  for(i in 1:2) { alpha[i] ~ dnorm(0,0.001)}   ## calibration priors
  sigma ~ dgamma(0.1,0.1)
  for(i in 1:10){
    ESMc[i] <- alpha[1] + alpha[2]*TDRc[i]   ## expected soil moisture, calibration
    SMc[i] ~ dnorm(ESMc[i],sigma)  	  ## data model
  }
  
  ## Seedling Density vs Soil Moisture
  for(i in 1:2) { beta[i] ~ dnorm(0,0.001)}   ## Poisson regression priors
  for(i in 1:n){
    ESM[i] <-  alpha[1] + alpha[2]*TDR[i]   ## Errors in Variables – process model
    SM[i] ~ dnorm(ESM[i],sigma)                 ## Errors in Variables – data model
    log(mu[i]) <- beta[1]+beta[2]*SM[i]        ## Poisson Regression – process model
    y[i] ~ dpois(mu[i])                                    ## Poisson Regression – data
  }

  ## Prediction
  for(i in 1:15){
    log(mup[i]) <- beta[1]+beta[2]*SMseq[i]	
    py[i] ~ dpois(mup[i])
  }
}
"
```


While this model looks larger and more complicated that most we've looked at in BUGS, it really just consists of a number of simple parts we've seen before.  The first part is the fitting of the calibration curve.  The second part involves using the calibration curve to estimate soil moisture and then fitting the Poisson regression of seedling density vs soil moisture.  The third part is just calculating the model credible interval and predictive interval over a sequence of soil moisture values (SMseq).  Unlike the conventional approach of performing each step sequentially, this approach propagates the error in each step into the final model.
	Reminder: you may want to specify initial conditions on the model parameters.  It is perfectly valid to use the previous estimates (e.g. Task 1) for the initial conditions.  For example, if I wanted to initialize alpha to all 0's and sigma to 5 I would specify list(alpha=c(0,0),sigma(5))
 
### Lab Report Task 5: 

14.  Fit the final combined calibration/Poisson regression model and provide a summary table and posterior density plots for the model parameters.  Also report the number of chains, length of each chain, burn in, thin, and the resultant MCMC sample size used to estimate the parameters. 
15.	Use the Comparison Tool to plot the model credible interval and predictive interval.  For this particular case the scatterplot of the observed data is NOT required as this is not straightforward in BUGS and would require outputting the posterior to other software (e.g. R) in order to make the graph.
16.	How does this fit compare to the previous Poisson regression of seedlings vs TDR in terms of the overall uncertainty in the model (width of credible and predictive intervals)?  In qualitative terms, to what degree does ignoring the uncertainty in the TDR/Soil Moisture relationship affect the uncertainty in our parameter estimates and our confidence in our model?



